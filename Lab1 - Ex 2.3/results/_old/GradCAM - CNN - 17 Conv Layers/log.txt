2024-06-25 17:56:40,025 - Starting run.
2024-06-25 17:56:40,026 - Logger setup correctly.
2024-06-25 17:56:40,027 - Seed set to 1.
2024-06-25 17:56:40,037 - Log filepath: results/GradCAM - CNN - 17 Conv Layers/log.txt.
2024-06-25 17:56:40,037 - Data dir: ../data.
2024-06-25 17:56:40,037 - Dataset: CIFAR10
2024-06-25 17:56:40,037 - Number of dataloader workers: 8
2024-06-25 17:56:40,037 - Network: CNN
2024-06-25 17:56:40,037 - Computation device: cuda:0
2024-06-25 17:56:40,037 - Loading dataset from "../data".
2024-06-25 17:56:42,777 - Dataset loaded.
2024-06-25 17:56:42,778 - Initializing CNN model.
2024-06-25 17:56:43,143 - Model initialized.
2024-06-25 17:56:43,143 - Showing model structure:
2024-06-25 17:56:43,143 - ConvolutionalNeuralNetwork(
  (conv_net): Sequential(
    (init_conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
    (conv_block_1): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
      )
    )
    (conv_block_2): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
    )
    (conv_block_3): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
      )
    )
    (conv_block_4): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
    )
    (conv_block_5): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
      )
    )
    (conv_block_6): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
        (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      )
    )
    (conv_block_7): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
      )
    )
    (conv_block_8): ConvolutionalBlock(
      (block_layers): Sequential(
        (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_1): ReLU()
        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)
        (bn_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (act_2): ReLU()
        (pool_hook): AdaptiveMaxPool2d(output_size=2)
      )
    )
  )
  (fc): MultiLayerPerceptron(
    (layers): Sequential(
      (linear_1): Linear(in_features=2048, out_features=1024, bias=False)
      (bn_1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act_1): ReLU()
      (linear_2): Linear(in_features=1024, out_features=1024, bias=False)
      (bn_2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act_2): ReLU()
      (last_linear): Linear(in_features=1024, out_features=10, bias=False)
    )
  )
)
2024-06-25 17:56:43,144 - Initializing AdamW optimizer.
2024-06-25 17:56:43,145 - Optimizer initialized.
2024-06-25 17:56:43,149 - Loading model from "../Lab1 - Ex 1.2/results/CNN - 17 Conv Layers/model.pth.tar".
2024-06-25 17:56:43,532 - Model loaded.
2024-06-25 17:56:43,532 - Explaining model predictions with Class Activation Mappings...
2024-06-25 17:56:46,845 - Finished explaining predictions with Class Activation Mappings..
2024-06-25 17:56:46,845 - Finished run.
2024-06-25 17:56:46,845 - Closing experiment.
