{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177cb78d-3425-433a-9239-4ee93677e2fc",
   "metadata": {},
   "source": [
    "# Out-Of-Distribution Data Detection\n",
    "\n",
    "In this simple example we will explore some aspects of the behavior of Deep Networks on Out-Of-Distribution (OOD) samples. We will train a shallow CNN on CIFAR-10 and see how the network responds to **random** inputs. In our laboratory next week we will follow up on this with some deeper analysis and some exercises related to generating **targeted** adversarial samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493066e7-eb78-49cf-b6f9-47b21ccfc57c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard imports.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import FakeData, CIFAR10, CIFAR100\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Select best device.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf335028-8051-4dc4-a853-0a144d8827cd",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "We will use the CIFAR-10 dataset as a basis for our analysis. It's reasonably small and its easy to find OOD samples for it (it's much harder for, say, *ImageNet*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162729bb-0c04-40d5-a02f-f7de8a65eedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use CIFAR-10 as our in-distribution dataset.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load the datasets and setup the DataLoaders.\n",
    "batch_size = 32\n",
    "ds_train = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "ds_test = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# In case we want to pretty-print classifications.\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbf062-0eb7-4bec-ba51-06892f0c4494",
   "metadata": {},
   "source": [
    "This is probably a dataset you have never used... `FakeData` generates images using *Gaussian noise*. Setup the dataset for 32x32 RGB images, and a corresponding DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd640b7-81e5-4946-a406-ccb1ad7d6ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fake dataset.\n",
    "ds_fake = FakeData(size=1000, image_size=(3, 32, 32), transform=transform)\n",
    "dl_fake = torch.utils.data.DataLoader(ds_fake, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Plot a fake image.\n",
    "plt.imshow(FakeData(size=1, image_size=(3, 32, 32))[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37804c95-021d-4f31-b35e-cd58a03647f3",
   "metadata": {},
   "source": [
    "### Our CNN\n",
    "\n",
    "This is a simple and shallow CNN model with only two convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70f65d-8fb9-49c6-b0a9-db9f5cd210bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A very simple CNN model.\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47330ae-4c0e-4ac9-aae6-362779d71109",
   "metadata": {},
   "source": [
    "### Training the base model\n",
    "\n",
    "We train our CNN on CIFAR-10 for a minimal number of epochs. Note, I have also uploaded the already-trained model for those of you without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892c725-5d59-48d0-9c2a-e258f131b256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE THIS CELL TO LOAD THE PRETRAINED MODEL.\n",
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load('./cifar10_CNN.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dc962-44e5-4f8f-a9ac-b1175b9e7878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USE THIS CELL TO TRAIN MODEL FROM SCRATCH.\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Train for only 50 epochs.\n",
    "epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Main training loop.\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    # Iterate over all batches.\n",
    "    for (i, (Xs, ys)) in enumerate(dl_train, 0):\n",
    "        Xs = Xs.to(device)\n",
    "        ys = ys.to(device)\n",
    "        \n",
    "        # Make a gradient step.\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(Xs)\n",
    "        loss = criterion(outputs, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track epoch loss.\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average epoch loss.\n",
    "    print(f'{epoch + 1} loss: {running_loss / len(dl_train):.3f}')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), './cifar10_CNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcab994-412d-49e0-81e4-20aa7055a0d0",
   "metadata": {},
   "source": [
    "### Analyzing In Distribution (ID) and OOD behavior.\n",
    "\n",
    "The simplest thing we could do, ideally, is just look at the logit response from the model. If the max logit is \"too low\", it *must* be an OOD sample. Let's try..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ee9ae-256f-4fc0-8d1f-540db29407e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to collect all logits from the model on entire dataset.\n",
    "def collect_logits(model, dl):\n",
    "    logits = []\n",
    "    with torch.no_grad():\n",
    "        for (Xs, _) in dl:\n",
    "            logits.append(model(Xs.to(device)).cpu().numpy())\n",
    "    return np.vstack(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa5df4-7d71-434b-afea-2d5d33065fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect logits on CIFAR-10 test set (ID) and noise (very OOD).\n",
    "logits_ID = collect_logits(model, dl_test)\n",
    "logits_OOD = collect_logits(model, dl_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e272c-7aeb-4dc2-8c7c-4a24c7df4186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the *distribution* of max logit outputs.\n",
    "_ = plt.hist(logits_ID.max(1), 50, density=True, alpha=0.5, label='ID')\n",
    "_ = plt.hist(logits_OOD.max(1), 50, density=True, alpha=0.5, label='OOD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b110dd-eaf4-4c54-ad71-2d907a32973b",
   "metadata": {},
   "source": [
    "### To think about\n",
    "\n",
    "Here are a few things to think and try out about before the next laboratory.\n",
    "\n",
    "1. Is looking at the max logit the *best* we can do using *just* the CNN outputs? Is there maybe a better way to try to gauge model *confidence* from the logits?\n",
    "\n",
    "2. Does the behavior of the network on OOD data get *better* or *worse* with more (or fewer) training epochs? \n",
    "\n",
    "2. Does the problem get worse if we test using *real* images as OOD samples? Find a subset of CIFAR-100 classes that are *distinct* from those in CIFAR-10 and test this theory.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
